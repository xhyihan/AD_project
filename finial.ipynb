{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nick\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory where our MRI .nii files are located!!!!\n",
    "mri_image_dir = '../ADNI_RESIZED2' \n",
    "\n",
    "# Use os.listdir -->to get all file names in this directory\n",
    "#Don't get the name one by one (which is what I did before\n",
    "mri_image_paths = [os.path.join(mri_image_dir, fname) for fname in os.listdir(mri_image_dir) if fname.endswith('.nii')]\n",
    "\n",
    "#print(\"Current working directory:\", os.getcwd())\n",
    "#print(\"Contents of the MRI directory:\", os.listdir(mri_image_dir))\n",
    "#print(\"Number of MRI files:\", len(mri_image_paths))\n",
    "#print(\"First 10 paths:\", mri_image_paths[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN architecture\n",
    "def create_3d_cnn_model(width, height, depth, num_classes):\n",
    "    inputShape = (width, height, depth, 1) \n",
    "    inputs = tf.keras.Input(inputShape)\n",
    "    \n",
    "    x = tf.keras.layers.Conv3D(32, (3, 3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv3D(64, (3, 3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = tf.keras.layers.GlobalAveragePooling3D()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess an MRI image\n",
    "def preprocess_and_extract_features_batch(file_paths, model):\n",
    "    batch_data = []\n",
    "    for file_path in file_paths:\n",
    "        # Load the MRI image (.nii file) using nibabel\n",
    "        image_data = nib.load(file_path)\n",
    "        data = image_data.get_fdata()\n",
    "        # Normalize the data and preprocess\n",
    "        data = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "        data = np.resize(data, (64, 64, 64))  # Resize\n",
    "        batch_data.append(data)\n",
    "    \n",
    "    batch_data = np.array(batch_data)\n",
    "    batch_data = np.expand_dims(batch_data, axis=-1) \n",
    "\n",
    "    # 3D CNN to extract features that we need\n",
    "    features = model.predict(batch_data)\n",
    "    return features.reshape((features.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nick\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Nick\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = create_3d_cnn_model(64, 64, 64, num_classes=2)  # num_classes=2 --> binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 930ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 462ms/step\n",
      "1/1 [==============================] - 0s 483ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n"
     ]
    }
   ],
   "source": [
    "# process images in batches\n",
    "batch_size = 10\n",
    "features_list = []\n",
    "\n",
    "for i in range(0, len(mri_image_paths), batch_size):\n",
    "    batch_paths = mri_image_paths[i:i + batch_size]\n",
    "    features = preprocess_and_extract_features_batch(batch_paths, model)\n",
    "    features_list.append(features)\n",
    "\n",
    "# Concatenate all batches to get the full features array\n",
    "features = np.concatenate(features_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../extracted_features.csv', features, delimiter=',')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Image Data ID     Subject Group Sex  Age  Visit Modality  \\\n",
      "0       I729725  941_S_5193   SMC   F   74     30      MRI   \n",
      "1       I388033  941_S_5193   SMC   F   73     24      MRI   \n",
      "2       I375627  941_S_5193   SMC   F   73     22      MRI   \n",
      "3       I388034  941_S_5193   SMC   F   73     24      MRI   \n",
      "4       I729737  941_S_5193   SMC   F   74     30      MRI   \n",
      "\n",
      "          Description       Type   Acq Date Format  Downloaded  \n",
      "0  MT1; GradWarp; N3m  Processed  4/02/2015  NiFTI         NaN  \n",
      "1  MT1; GradWarp; N3m  Processed  8/19/2013  NiFTI         NaN  \n",
      "2  MT1; GradWarp; N3m  Processed  5/29/2013  NiFTI         NaN  \n",
      "3  MT1; GradWarp; N3m  Processed  8/19/2013  NiFTI         NaN  \n",
      "4  MT1; GradWarp; N3m  Processed  4/02/2015  NiFTI         NaN  \n",
      "[('I729725', 'SMC'), ('I388033', 'SMC'), ('I375627', 'SMC'), ('I388034', 'SMC'), ('I729737', 'SMC')]\n",
      "['I71281', 'I32674', 'I67669', 'I67678', 'I74185']\n",
      "File: ../ADNI_RESIZED2\\ADNI_003_S_0931_MR_MPR__GradWarp__B1_Correction_Br_20070904172827571_S30780_I71281.nii - Label: CN\n",
      "File: ../ADNI_RESIZED2\\ADNI_005_S_0602_MR_MPR__GradWarp__B1_Correction_Br_20061212103555520_S15966_I32674.nii - Label: CN\n",
      "File: ../ADNI_RESIZED2\\ADNI_005_S_0602_MR_MPR__GradWarp__B1_Correction_Br_20070815092719244_S25188_I67669.nii - Label: CN\n",
      "File: ../ADNI_RESIZED2\\ADNI_005_S_0602_MR_MPR__GradWarp__B1_Correction_Br_20070815093817484_S25967_I67678.nii - Label: CN\n",
      "File: ../ADNI_RESIZED2\\ADNI_005_S_0602_MR_MPR__GradWarp__B1_Correction_Br_20070921133538231_S37063_I74185.nii - Label: CN\n",
      "First 10 feature-label pairs:\n",
      "Feature 0: [0.4959281 0.5040719]\n",
      "Label 0: CN\n",
      "Feature 1: [0.49883464 0.5011653 ]\n",
      "Label 1: CN\n",
      "Feature 2: [0.4988712 0.5011288]\n",
      "Label 2: CN\n",
      "Feature 3: [0.4987011  0.50129884]\n",
      "Label 3: CN\n",
      "Feature 4: [0.49864608 0.50135386]\n",
      "Label 4: CN\n",
      "Feature 5: [0.49887967 0.5011204 ]\n",
      "Label 5: CN\n",
      "Feature 6: [0.49857292 0.50142705]\n",
      "Label 6: CN\n",
      "Feature 7: [0.49864462 0.50135535]\n",
      "Label 7: CN\n",
      "Feature 8: [0.49867693 0.5013231 ]\n",
      "Label 8: CN\n",
      "Feature 9: [0.49890047 0.50109947]\n",
      "Label 9: AD\n"
     ]
    }
   ],
   "source": [
    "# Read\n",
    "labels_df = pd.read_csv('../Labels.csv')\n",
    "print(labels_df.head())\n",
    "\n",
    "# Create a dictionary mapping  Image Data ID and label\n",
    "labels_dict = dict(zip(labels_df['Image Data ID'], labels_df['Group']))\n",
    "print(list(labels_dict.items())[:5])\n",
    "\n",
    "# extract the Image Data ID from the file name\n",
    "def extract_image_data_id(filename):\n",
    "    match = re.match(r'.*_(I\\d+)\\.nii', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None  # Return None if the pattern does not match\n",
    "\n",
    "# Extract the Image Data ID from each filename\n",
    "mri_image_ids = [extract_image_data_id(os.path.basename(path)) for path in mri_image_paths]\n",
    "print(list(mri_image_ids)[:5])\n",
    "\n",
    "# Debug\n",
    "mri_image_paths = [os.path.join(mri_image_dir, fname) for fname in os.listdir(mri_image_dir) if fname.endswith('.nii')]\n",
    "mri_image_labels = [labels_dict.get(extract_image_data_id(os.path.basename(path))) for path in mri_image_paths]\n",
    "for path, label in zip(mri_image_paths[:5], mri_image_labels[:5]):\n",
    "    print(f'File: {path} - Label: {label}')\n",
    "\n",
    "# only use images for which we have labels\n",
    "# a list for features and labels where labels are available\n",
    "filtered_features = []\n",
    "filtered_labels = []\n",
    "for image_id, feature in zip(mri_image_ids, features):\n",
    "    label = labels_dict.get(image_id)\n",
    "    if label is not None:\n",
    "        filtered_features.append(feature)\n",
    "        filtered_labels.append(label)\n",
    "\n",
    "# Convert \n",
    "filtered_features = np.array(filtered_features)\n",
    "filtered_labels = np.array(filtered_labels)\n",
    "\n",
    "# Debug\n",
    "print(\"First 10 feature-label pairs:\")\n",
    "for i in range(min(10, len(filtered_features))):  \n",
    "    print(f\"Feature {i}:\", filtered_features[i])\n",
    "    print(f\"Label {i}:\", filtered_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(filtered_features, filtered_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier on the features extracted by the 3D CNN\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "#np.savetxt('predictions.csv', y_pred, delimiter=',')\n",
    "np.savetxt('../predictions.csv', y_pred, fmt='%s', delimiter=',')\n",
    "\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classification report to a text file\n",
    "with open('../classification_report.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "# Save the model's accuracy to a text file\n",
    "with open('../model_accuracy.txt', 'w') as f:\n",
    "    f.write(f\"Accuracy: {accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2782608695652174\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.15      0.18      0.17        22\n",
      "          CN       0.23      0.25      0.24        40\n",
      "         MCI       0.39      0.34      0.36        53\n",
      "\n",
      "    accuracy                           0.28       115\n",
      "   macro avg       0.26      0.26      0.26       115\n",
      "weighted avg       0.29      0.28      0.28       115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Output the accuracy and classification report\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
